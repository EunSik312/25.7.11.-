{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EunSik312/25.7.11.-/blob/main/7%EC%9B%9415%EC%9D%BC_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#교육용 CNN 코드"
      ],
      "metadata": {
        "id": "aKTFcwkO6nuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Dense(128, activation='relu'),\n",
        "\n",
        " Dense(3, activation='softmax')  \n",
        "\n",
        " # Animal/Car/Other"
      ],
      "metadata": {
        "id": "fNW8xUNJ6uuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # 기본 사용 예시\n",
        " # 이코드는 사진하나 입력해서 출력하는 시각화 pillow라는 라이브러리인데 간단하게 테스트\n",
        " from PIL import Image, ImageFilter, ImageDraw\n",
        " # 이미지 열기 img = Image.open('photo.jpg')\n",
        " # 기본 정보 확인 print(f\"크기: {img.size}\") print(f\"모드: {img.mode}\") print(f\"형식: {img.format}\")\n",
        " # 크기 조정 resized = img.resize((800, 600))\n",
        " # 회전 rotated = img.rotate(45)\n",
        " # 필터 적용 blurred = img.filter(ImageFilter.BLUR)\n",
        " # 저장 img.save('output.png')"
      ],
      "metadata": {
        "id": "qJ0v83lJ76LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📘 진짜 CNN 교육용 데모 - Google Colab용\n",
        "# 사진 하나 업로드로 CNN 체험하기!\n",
        "\n",
        "# 🔧 필요한 라이브러리 설치\n",
        "!pip install tensorflow matplotlib pillow numpy\n",
        "\n",
        "# 📦 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io"
      ],
      "metadata": {
        "id": "Mnz6p8756RBj",
        "outputId": "920fade7-bffc-4ccf-d0e9-ee45bd1cbfcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧠 간단한 CNN 모델 생성\n",
        "def create_simple_cnn():\n",
        "    \"\"\"\n",
        "    교육용 간단한 CNN 모델 생성\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        # 첫 번째 컨볼루션 레이어\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # 두 번째 컨볼루션 레이어\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # 세 번째 컨볼루션 레이어\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # Flatten & Dense 레이어\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(3, activation='softmax')  # 3 classes: Animal/Car/Other\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "LjArHAO06S7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # 모델 컴파일\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"🧠 CNN 모델 생성 완료!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ajpj3Iv06Taq",
        "outputId": "67aa13cc-acb9-4e97-f625-4f920cd2b6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-4-1231227023.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4-1231227023.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model.compile(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📊 CNN 구조 시각화\n",
        "def visualize_model_architecture(model):\n",
        "    \"\"\"\n",
        "    CNN 모델 구조를 시각적으로 보여주기\n",
        "    \"\"\"\n",
        "    print(\"\\n📋 CNN 모델 구조:\")\n",
        "    print(\"=\" * 50)\n",
        "    model.summary()\n",
        "\n",
        "    # 레이어별 설명\n",
        "    print(\"\\n🔍 레이어별 역할:\")\n",
        "    print(\"📌 Conv2D: 특징 추출 (엣지, 패턴 등)\")\n",
        "    print(\"📌 MaxPooling2D: 크기 축소 + 중요 특징 선택\")\n",
        "    print(\"📌 Flatten: 2D → 1D 변환\")\n",
        "    print(\"📌 Dense: 최종 분류 결정\")\n",
        "    print(\"📌 Dropout: 과적합 방지\")\n"
      ],
      "metadata": {
        "id": "5gYOsD9P6VoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎲 가짜 데이터로 빠른 훈련\n",
        "def quick_train_with_dummy_data(model):\n",
        "    \"\"\"\n",
        "    데모용 가짜 데이터로 빠른 훈련\n",
        "    \"\"\"\n",
        "    print(\"\\n🎓 데모용 빠른 훈련 시작...\")\n",
        "\n",
        "    # 가짜 훈련 데이터 생성 (200개 샘플)\n",
        "    X_train = np.random.rand(200, 64, 64, 3).astype('float32')\n",
        "    y_train = tf.keras.utils.to_categorical(np.random.randint(0, 3, 200), 3)\n",
        "\n",
        "    # 빠른 훈련 (3 epochs만)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=3,\n",
        "        batch_size=32,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"✅ 훈련 완료! (실제 프로젝트에서는 실제 데이터 사용)\")\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "8oBonqvR6XWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔍 CNN 필터 시각화\n",
        "def visualize_cnn_filters(model):\n",
        "    \"\"\"\n",
        "    CNN 첫 번째 레이어의 학습된 필터들 시각화\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 모델이 빌드되었는지 확인\n",
        "        if not hasattr(model, 'built') or not model.built:\n",
        "            print(\"⚠️ 모델을 빌드하는 중...\")\n",
        "            dummy_input = np.random.rand(1, 64, 64, 3)\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "        # 첫 번째 Conv2D 레이어 찾기\n",
        "        first_conv_layer = None\n",
        "        for layer in model.layers:\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "                first_conv_layer = layer\n",
        "                break\n",
        "\n",
        "        if first_conv_layer is None:\n",
        "            print(\"❌ Conv2D 레이어를 찾을 수 없습니다.\")\n",
        "            return\n",
        "\n",
        "        # 첫 번째 Conv2D 레이어의 가중치 추출\n",
        "        weights = first_conv_layer.get_weights()\n",
        "        if len(weights) == 0:\n",
        "            print(\"⚠️ 아직 가중치가 초기화되지 않았습니다.\")\n",
        "            return\n",
        "\n",
        "        filters = weights[0]  # 필터 가중치\n",
        "\n",
        "        print(f\"\\n🔍 첫 번째 레이어 필터 시각화\")\n",
        "        print(f\"필터 개수: {filters.shape[3]}개\")\n",
        "        print(f\"필터 크기: {filters.shape[0]}x{filters.shape[1]}\")\n",
        "\n",
        "        # 필터 중 처음 8개만 시각화\n",
        "        num_filters_to_show = min(8, filters.shape[3])\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "        fig.suptitle('CNN Learned Filters (First Layer)', fontsize=16)\n",
        "\n",
        "        for i in range(num_filters_to_show):\n",
        "            ax = axes[i // 4, i % 4]\n",
        "\n",
        "            # 필터를 시각화하기 위해 정규화\n",
        "            filter_img = filters[:, :, 0, i]  # 첫 번째 채널의 i번째 필터\n",
        "\n",
        "            # 정규화 (0-1 범위로)\n",
        "            if filter_img.max() > filter_img.min():\n",
        "                filter_img = (filter_img - filter_img.min()) / (filter_img.max() - filter_img.min())\n",
        "\n",
        "            ax.imshow(filter_img, cmap='viridis')\n",
        "            ax.set_title(f'Filter {i+1}')\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 필터 시각화 중 오류 발생: {str(e)}\")\n",
        "        print(\"💡 이는 모델 구조나 가중치 이슈일 수 있습니다.\")\n",
        "        print(\"📝 주요 기능(예측)은 정상 작동합니다!\")\n"
      ],
      "metadata": {
        "id": "ggjNIxKp6ali"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📸 이미지 업로드 및 전처리\n",
        "def upload_and_preprocess_image():\n",
        "    \"\"\"\n",
        "    이미지 업로드 및 CNN 입력용 전처리\n",
        "    \"\"\"\n",
        "    print(\"📸 이미지를 업로드해주세요!\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    image_data = uploaded[filename]\n",
        "\n",
        "    # 이미지 로드 및 전처리\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # RGB로 변환 (RGBA인 경우)\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "    # 크기 조정 (64x64)\n",
        "    image_resized = image.resize((64, 64))\n",
        "\n",
        "    # 배열로 변환 및 정규화\n",
        "    image_array = np.array(image_resized).astype('float32') / 255.0\n",
        "\n",
        "    # 배치 차원 추가 (1, 64, 64, 3)\n",
        "    image_batch = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    return image, image_resized, image_batch, filename\n"
      ],
      "metadata": {
        "id": "CbUPnwR16b-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎯 CNN 예측 및 결과 시각화\n",
        "def predict_and_visualize(model, original_img, processed_img, image_batch, filename):\n",
        "    \"\"\"\n",
        "    CNN으로 예측하고 결과 시각화\n",
        "    \"\"\"\n",
        "    # 클래스 라벨 정의\n",
        "    class_names = ['Animal', 'Car', 'Other']\n",
        "\n",
        "    # CNN 예측\n",
        "    predictions = model.predict(image_batch, verbose=0)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class]\n",
        "\n",
        "    # 결과 시각화\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # 원본 이미지\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(original_img)\n",
        "    plt.title(f'original image\\n({filename})')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 전처리된 이미지 (CNN 입력)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(processed_img)\n",
        "    plt.title('CNN input image\\n(64x64 크기 조정)')\n",
        "    plt.axis('off')\n"
      ],
      "metadata": {
        "id": "Wdvl9sYd6dbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 예측 결과\n",
        "    plt.subplot(1, 3, 3)\n",
        "    bars = plt.bar(class_names, predictions[0])\n",
        "    bars[predicted_class].set_color('red')  # 최고 확률 클래스 강조\n",
        "    plt.title(f'CNN Prediction Results\\nPrediction: {class_names[predicted_class]} ({confidence:.2%})')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    # 확률 값 표시\n",
        "    for i, (name, prob) in enumerate(zip(class_names, predictions[0])):\n",
        "        plt.text(i, prob + 0.02, f'{prob:.2%}', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 결과 출력\n",
        "    print(\"\\n🎯 CNN Prediction Results:\")\n",
        "    print(\"=\" * 30)\n",
        "    for i, (name, prob) in enumerate(zip(class_names, predictions[0])):\n",
        "        marker = \"👉\" if i == predicted_class else \"  \"\n",
        "        print(f\"{marker} {name}: {prob:.2%}\")\n",
        "    print(\"=\" * 30)\n",
        "    print(f\"Final Prediction: {class_names[predicted_class]} (Confidence: {confidence:.2%})\")\n"
      ],
      "metadata": {
        "id": "XexJQMN86d_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔬 CNN 중간 레이어 활성화 시각화\n",
        "def visualize_intermediate_activations(model, image_batch):\n",
        "    \"\"\"\n",
        "    CNN 중간 레이어들의 활성화 맵 시각화\n",
        "    \"\"\"\n",
        "    print(\"\\n🔬 CNN 내부 작동 과정 시각화...\")\n",
        "\n",
        "    try:\n",
        "        # 모델이 빌드되었는지 확인\n",
        "        if not hasattr(model, 'built') or not model.built:\n",
        "            print(\"⚠️ 모델을 빌드하는 중...\")\n",
        "            # 더미 데이터로 모델 빌드\n",
        "            dummy_input = np.random.rand(1, 64, 64, 3)\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "        # Conv2D 레이어만 찾기\n",
        "        conv_layers = []\n",
        "        layer_names = []\n",
        "\n",
        "        for i, layer in enumerate(model.layers):\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "                conv_layers.append(layer)\n",
        "                layer_names.append(f'Conv2D Layer {len(conv_layers)}')\n",
        "\n",
        "        if len(conv_layers) == 0:\n",
        "            print(\"❌ Conv2D 레이어를 찾을 수 없습니다.\")\n",
        "            return\n",
        "\n",
        "        # 중간 레이어 출력을 위한 모델 생성\n",
        "        layer_outputs = [layer.output for layer in conv_layers]\n",
        "        activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "        # 활성화 맵 계산\n",
        "        activations = activation_model.predict(image_batch, verbose=0)\n",
        "\n",
        "        # 단일 출력인 경우 리스트로 변환\n",
        "        if not isinstance(activations, list):\n",
        "            activations = [activations]\n",
        "\n",
        "        # 시각화\n",
        "        num_layers = min(3, len(conv_layers))  # 최대 3개 레이어만\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            activation = activations[i]\n",
        "            layer_name = layer_names[i]\n",
        "\n",
        "            # 처음 4개 필터만 표시\n",
        "            num_filters = min(4, activation.shape[-1])\n",
        "            for j in range(num_filters):\n",
        "                plt.subplot(num_layers, 4, i*4 + j + 1)\n",
        "\n",
        "                # 활성화 맵 정규화\n",
        "                feature_map = activation[0, :, :, j]\n",
        "                if feature_map.max() > feature_map.min():\n",
        "                    feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())\n",
        "\n",
        "                plt.imshow(feature_map, cmap='viridis')\n",
        "                plt.title(f'{layer_name}\\nFilter {j+1}')\n",
        "                plt.axis('off')\n",
        "\n",
        "        plt.suptitle('CNN Feature Maps - How CNN \"Sees\" Your Image', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"💡 해석:\")\n",
        "        print(\"- 첫 번째 레이어: 기본적인 엣지, 색상 검출\")\n",
        "        print(\"- 두 번째 레이어: 더 복잡한 패턴 조합\")\n",
        "        print(\"- 세 번째 레이어: 고수준 특징 (객체 부분)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 활성화 시각화 중 오류 발생: {str(e)}\")\n",
        "        print(\"💡 이는 모델 구조나 TensorFlow 버전 이슈일 수 있습니다.\")\n",
        "        print(\"📝 주요 기능(예측)은 정상 작동합니다!\")\n"
      ],
      "metadata": {
        "id": "bScM15hz6gKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎮 메인 실행 함수\n",
        "def run_cnn_demo():\n",
        "    \"\"\"\n",
        "    CNN 교육용 데모 메인 실행\n",
        "    \"\"\"\n",
        "    print(\"🎉 진짜 CNN 교육용 데모 시작!\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. CNN 모델 생성\n",
        "    model = create_simple_cnn()\n",
        "\n",
        "    # 2. 모델 구조 확인\n",
        "    visualize_model_architecture(model)\n",
        "\n",
        "    # 3. 빠른 훈련 (데모용)\n",
        "    history = quick_train_with_dummy_data(model)\n",
        "\n",
        "    # 4. 학습된 필터 시각화\n",
        "    visualize_cnn_filters(model)\n",
        "\n",
        "    # 5. 이미지 업로드 및 예측\n",
        "    original_img, processed_img, image_batch, filename = upload_and_preprocess_image()\n",
        "\n",
        "    # 6. CNN 예측 및 결과 시각화\n",
        "    predict_and_visualize(model, original_img, processed_img, image_batch, filename)\n",
        "\n",
        "    # 7. CNN 내부 작동 과정 시각화\n",
        "    visualize_intermediate_activations(model, image_batch)\n",
        "\n",
        "    print(\"\\n🎓 CNN 데모 완료!\")\n",
        "    print(\"💡 이제 CNN이 어떻게 이미지를 '이해'하는지 보셨습니다!\")\n",
        "\n",
        "# 🚀 데모 실행\n",
        "print(\"📚 CNN 교육용 데모 - 실제 신경망으로 이미지 분류 체험\")\n",
        "print(\"🔥 이번에는 진짜 CNN입니다!\")\n",
        "print()\n",
        "run_cnn_demo()"
      ],
      "metadata": {
        "id": "SFus-Shj6ijy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}