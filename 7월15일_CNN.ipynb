{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EunSik312/25.7.11.-/blob/main/7%EC%9B%9415%EC%9D%BC_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#êµìœ¡ìš© CNN ì½”ë“œ"
      ],
      "metadata": {
        "id": "aKTFcwkO6nuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Dense(128, activation='relu'),\n",
        "\n",
        " Dense(3, activation='softmax')  \n",
        "\n",
        " # Animal/Car/Other"
      ],
      "metadata": {
        "id": "fNW8xUNJ6uuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # ê¸°ë³¸ ì‚¬ìš© ì˜ˆì‹œ\n",
        " # ì´ì½”ë“œëŠ” ì‚¬ì§„í•˜ë‚˜ ì…ë ¥í•´ì„œ ì¶œë ¥í•˜ëŠ” ì‹œê°í™” pillowë¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ë° ê°„ë‹¨í•˜ê²Œ í…ŒìŠ¤íŠ¸\n",
        " from PIL import Image, ImageFilter, ImageDraw\n",
        " # ì´ë¯¸ì§€ ì—´ê¸° img = Image.open('photo.jpg')\n",
        " # ê¸°ë³¸ ì •ë³´ í™•ì¸ print(f\"í¬ê¸°: {img.size}\") print(f\"ëª¨ë“œ: {img.mode}\") print(f\"í˜•ì‹: {img.format}\")\n",
        " # í¬ê¸° ì¡°ì • resized = img.resize((800, 600))\n",
        " # íšŒì „ rotated = img.rotate(45)\n",
        " # í•„í„° ì ìš© blurred = img.filter(ImageFilter.BLUR)\n",
        " # ì €ì¥ img.save('output.png')"
      ],
      "metadata": {
        "id": "qJ0v83lJ76LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“˜ ì§„ì§œ CNN êµìœ¡ìš© ë°ëª¨ - Google Colabìš©\n",
        "# ì‚¬ì§„ í•˜ë‚˜ ì—…ë¡œë“œë¡œ CNN ì²´í—˜í•˜ê¸°!\n",
        "\n",
        "# ğŸ”§ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install tensorflow matplotlib pillow numpy\n",
        "\n",
        "# ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io"
      ],
      "metadata": {
        "id": "Mnz6p8756RBj",
        "outputId": "920fade7-bffc-4ccf-d0e9-ee45bd1cbfcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§  ê°„ë‹¨í•œ CNN ëª¨ë¸ ìƒì„±\n",
        "def create_simple_cnn():\n",
        "    \"\"\"\n",
        "    êµìœ¡ìš© ê°„ë‹¨í•œ CNN ëª¨ë¸ ìƒì„±\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # ì„¸ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # Flatten & Dense ë ˆì´ì–´\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(3, activation='softmax')  # 3 classes: Animal/Car/Other\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "LjArHAO06S7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # ëª¨ë¸ ì»´íŒŒì¼\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"ğŸ§  CNN ëª¨ë¸ ìƒì„± ì™„ë£Œ!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ajpj3Iv06Taq",
        "outputId": "67aa13cc-acb9-4e97-f625-4f920cd2b6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-4-1231227023.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4-1231227023.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model.compile(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“Š CNN êµ¬ì¡° ì‹œê°í™”\n",
        "def visualize_model_architecture(model):\n",
        "    \"\"\"\n",
        "    CNN ëª¨ë¸ êµ¬ì¡°ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ê¸°\n",
        "    \"\"\"\n",
        "    print(\"\\nğŸ“‹ CNN ëª¨ë¸ êµ¬ì¡°:\")\n",
        "    print(\"=\" * 50)\n",
        "    model.summary()\n",
        "\n",
        "    # ë ˆì´ì–´ë³„ ì„¤ëª…\n",
        "    print(\"\\nğŸ” ë ˆì´ì–´ë³„ ì—­í• :\")\n",
        "    print(\"ğŸ“Œ Conv2D: íŠ¹ì§• ì¶”ì¶œ (ì—£ì§€, íŒ¨í„´ ë“±)\")\n",
        "    print(\"ğŸ“Œ MaxPooling2D: í¬ê¸° ì¶•ì†Œ + ì¤‘ìš” íŠ¹ì§• ì„ íƒ\")\n",
        "    print(\"ğŸ“Œ Flatten: 2D â†’ 1D ë³€í™˜\")\n",
        "    print(\"ğŸ“Œ Dense: ìµœì¢… ë¶„ë¥˜ ê²°ì •\")\n",
        "    print(\"ğŸ“Œ Dropout: ê³¼ì í•© ë°©ì§€\")\n"
      ],
      "metadata": {
        "id": "5gYOsD9P6VoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ² ê°€ì§œ ë°ì´í„°ë¡œ ë¹ ë¥¸ í›ˆë ¨\n",
        "def quick_train_with_dummy_data(model):\n",
        "    \"\"\"\n",
        "    ë°ëª¨ìš© ê°€ì§œ ë°ì´í„°ë¡œ ë¹ ë¥¸ í›ˆë ¨\n",
        "    \"\"\"\n",
        "    print(\"\\nğŸ“ ë°ëª¨ìš© ë¹ ë¥¸ í›ˆë ¨ ì‹œì‘...\")\n",
        "\n",
        "    # ê°€ì§œ í›ˆë ¨ ë°ì´í„° ìƒì„± (200ê°œ ìƒ˜í”Œ)\n",
        "    X_train = np.random.rand(200, 64, 64, 3).astype('float32')\n",
        "    y_train = tf.keras.utils.to_categorical(np.random.randint(0, 3, 200), 3)\n",
        "\n",
        "    # ë¹ ë¥¸ í›ˆë ¨ (3 epochsë§Œ)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=3,\n",
        "        batch_size=32,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"âœ… í›ˆë ¨ ì™„ë£Œ! (ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì‹¤ì œ ë°ì´í„° ì‚¬ìš©)\")\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "8oBonqvR6XWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ” CNN í•„í„° ì‹œê°í™”\n",
        "def visualize_cnn_filters(model):\n",
        "    \"\"\"\n",
        "    CNN ì²« ë²ˆì§¸ ë ˆì´ì–´ì˜ í•™ìŠµëœ í•„í„°ë“¤ ì‹œê°í™”\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ëª¨ë¸ì´ ë¹Œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "        if not hasattr(model, 'built') or not model.built:\n",
        "            print(\"âš ï¸ ëª¨ë¸ì„ ë¹Œë“œí•˜ëŠ” ì¤‘...\")\n",
        "            dummy_input = np.random.rand(1, 64, 64, 3)\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "        # ì²« ë²ˆì§¸ Conv2D ë ˆì´ì–´ ì°¾ê¸°\n",
        "        first_conv_layer = None\n",
        "        for layer in model.layers:\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "                first_conv_layer = layer\n",
        "                break\n",
        "\n",
        "        if first_conv_layer is None:\n",
        "            print(\"âŒ Conv2D ë ˆì´ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        # ì²« ë²ˆì§¸ Conv2D ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ ì¶”ì¶œ\n",
        "        weights = first_conv_layer.get_weights()\n",
        "        if len(weights) == 0:\n",
        "            print(\"âš ï¸ ì•„ì§ ê°€ì¤‘ì¹˜ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        filters = weights[0]  # í•„í„° ê°€ì¤‘ì¹˜\n",
        "\n",
        "        print(f\"\\nğŸ” ì²« ë²ˆì§¸ ë ˆì´ì–´ í•„í„° ì‹œê°í™”\")\n",
        "        print(f\"í•„í„° ê°œìˆ˜: {filters.shape[3]}ê°œ\")\n",
        "        print(f\"í•„í„° í¬ê¸°: {filters.shape[0]}x{filters.shape[1]}\")\n",
        "\n",
        "        # í•„í„° ì¤‘ ì²˜ìŒ 8ê°œë§Œ ì‹œê°í™”\n",
        "        num_filters_to_show = min(8, filters.shape[3])\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "        fig.suptitle('CNN Learned Filters (First Layer)', fontsize=16)\n",
        "\n",
        "        for i in range(num_filters_to_show):\n",
        "            ax = axes[i // 4, i % 4]\n",
        "\n",
        "            # í•„í„°ë¥¼ ì‹œê°í™”í•˜ê¸° ìœ„í•´ ì •ê·œí™”\n",
        "            filter_img = filters[:, :, 0, i]  # ì²« ë²ˆì§¸ ì±„ë„ì˜ ië²ˆì§¸ í•„í„°\n",
        "\n",
        "            # ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ)\n",
        "            if filter_img.max() > filter_img.min():\n",
        "                filter_img = (filter_img - filter_img.min()) / (filter_img.max() - filter_img.min())\n",
        "\n",
        "            ax.imshow(filter_img, cmap='viridis')\n",
        "            ax.set_title(f'Filter {i+1}')\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ í•„í„° ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
        "        print(\"ğŸ’¡ ì´ëŠ” ëª¨ë¸ êµ¬ì¡°ë‚˜ ê°€ì¤‘ì¹˜ ì´ìŠˆì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "        print(\"ğŸ“ ì£¼ìš” ê¸°ëŠ¥(ì˜ˆì¸¡)ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!\")\n"
      ],
      "metadata": {
        "id": "ggjNIxKp6ali"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "def upload_and_preprocess_image():\n",
        "    \"\"\"\n",
        "    ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° CNN ì…ë ¥ìš© ì „ì²˜ë¦¬\n",
        "    \"\"\"\n",
        "    print(\"ğŸ“¸ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    image_data = uploaded[filename]\n",
        "\n",
        "    # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    # RGBë¡œ ë³€í™˜ (RGBAì¸ ê²½ìš°)\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "    # í¬ê¸° ì¡°ì • (64x64)\n",
        "    image_resized = image.resize((64, 64))\n",
        "\n",
        "    # ë°°ì—´ë¡œ ë³€í™˜ ë° ì •ê·œí™”\n",
        "    image_array = np.array(image_resized).astype('float32') / 255.0\n",
        "\n",
        "    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (1, 64, 64, 3)\n",
        "    image_batch = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "    return image, image_resized, image_batch, filename\n"
      ],
      "metadata": {
        "id": "CbUPnwR16b-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ CNN ì˜ˆì¸¡ ë° ê²°ê³¼ ì‹œê°í™”\n",
        "def predict_and_visualize(model, original_img, processed_img, image_batch, filename):\n",
        "    \"\"\"\n",
        "    CNNìœ¼ë¡œ ì˜ˆì¸¡í•˜ê³  ê²°ê³¼ ì‹œê°í™”\n",
        "    \"\"\"\n",
        "    # í´ë˜ìŠ¤ ë¼ë²¨ ì •ì˜\n",
        "    class_names = ['Animal', 'Car', 'Other']\n",
        "\n",
        "    # CNN ì˜ˆì¸¡\n",
        "    predictions = model.predict(image_batch, verbose=0)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class]\n",
        "\n",
        "    # ê²°ê³¼ ì‹œê°í™”\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # ì›ë³¸ ì´ë¯¸ì§€\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(original_img)\n",
        "    plt.title(f'original image\\n({filename})')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (CNN ì…ë ¥)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(processed_img)\n",
        "    plt.title('CNN input image\\n(64x64 í¬ê¸° ì¡°ì •)')\n",
        "    plt.axis('off')\n"
      ],
      "metadata": {
        "id": "Wdvl9sYd6dbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # ì˜ˆì¸¡ ê²°ê³¼\n",
        "    plt.subplot(1, 3, 3)\n",
        "    bars = plt.bar(class_names, predictions[0])\n",
        "    bars[predicted_class].set_color('red')  # ìµœê³  í™•ë¥  í´ë˜ìŠ¤ ê°•ì¡°\n",
        "    plt.title(f'CNN Prediction Results\\nPrediction: {class_names[predicted_class]} ({confidence:.2%})')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    # í™•ë¥  ê°’ í‘œì‹œ\n",
        "    for i, (name, prob) in enumerate(zip(class_names, predictions[0])):\n",
        "        plt.text(i, prob + 0.02, f'{prob:.2%}', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ê²°ê³¼ ì¶œë ¥\n",
        "    print(\"\\nğŸ¯ CNN Prediction Results:\")\n",
        "    print(\"=\" * 30)\n",
        "    for i, (name, prob) in enumerate(zip(class_names, predictions[0])):\n",
        "        marker = \"ğŸ‘‰\" if i == predicted_class else \"  \"\n",
        "        print(f\"{marker} {name}: {prob:.2%}\")\n",
        "    print(\"=\" * 30)\n",
        "    print(f\"Final Prediction: {class_names[predicted_class]} (Confidence: {confidence:.2%})\")\n"
      ],
      "metadata": {
        "id": "XexJQMN86d_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¬ CNN ì¤‘ê°„ ë ˆì´ì–´ í™œì„±í™” ì‹œê°í™”\n",
        "def visualize_intermediate_activations(model, image_batch):\n",
        "    \"\"\"\n",
        "    CNN ì¤‘ê°„ ë ˆì´ì–´ë“¤ì˜ í™œì„±í™” ë§µ ì‹œê°í™”\n",
        "    \"\"\"\n",
        "    print(\"\\nğŸ”¬ CNN ë‚´ë¶€ ì‘ë™ ê³¼ì • ì‹œê°í™”...\")\n",
        "\n",
        "    try:\n",
        "        # ëª¨ë¸ì´ ë¹Œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "        if not hasattr(model, 'built') or not model.built:\n",
        "            print(\"âš ï¸ ëª¨ë¸ì„ ë¹Œë“œí•˜ëŠ” ì¤‘...\")\n",
        "            # ë”ë¯¸ ë°ì´í„°ë¡œ ëª¨ë¸ ë¹Œë“œ\n",
        "            dummy_input = np.random.rand(1, 64, 64, 3)\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "        # Conv2D ë ˆì´ì–´ë§Œ ì°¾ê¸°\n",
        "        conv_layers = []\n",
        "        layer_names = []\n",
        "\n",
        "        for i, layer in enumerate(model.layers):\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "                conv_layers.append(layer)\n",
        "                layer_names.append(f'Conv2D Layer {len(conv_layers)}')\n",
        "\n",
        "        if len(conv_layers) == 0:\n",
        "            print(\"âŒ Conv2D ë ˆì´ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        # ì¤‘ê°„ ë ˆì´ì–´ ì¶œë ¥ì„ ìœ„í•œ ëª¨ë¸ ìƒì„±\n",
        "        layer_outputs = [layer.output for layer in conv_layers]\n",
        "        activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "        # í™œì„±í™” ë§µ ê³„ì‚°\n",
        "        activations = activation_model.predict(image_batch, verbose=0)\n",
        "\n",
        "        # ë‹¨ì¼ ì¶œë ¥ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
        "        if not isinstance(activations, list):\n",
        "            activations = [activations]\n",
        "\n",
        "        # ì‹œê°í™”\n",
        "        num_layers = min(3, len(conv_layers))  # ìµœëŒ€ 3ê°œ ë ˆì´ì–´ë§Œ\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            activation = activations[i]\n",
        "            layer_name = layer_names[i]\n",
        "\n",
        "            # ì²˜ìŒ 4ê°œ í•„í„°ë§Œ í‘œì‹œ\n",
        "            num_filters = min(4, activation.shape[-1])\n",
        "            for j in range(num_filters):\n",
        "                plt.subplot(num_layers, 4, i*4 + j + 1)\n",
        "\n",
        "                # í™œì„±í™” ë§µ ì •ê·œí™”\n",
        "                feature_map = activation[0, :, :, j]\n",
        "                if feature_map.max() > feature_map.min():\n",
        "                    feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())\n",
        "\n",
        "                plt.imshow(feature_map, cmap='viridis')\n",
        "                plt.title(f'{layer_name}\\nFilter {j+1}')\n",
        "                plt.axis('off')\n",
        "\n",
        "        plt.suptitle('CNN Feature Maps - How CNN \"Sees\" Your Image', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"ğŸ’¡ í•´ì„:\")\n",
        "        print(\"- ì²« ë²ˆì§¸ ë ˆì´ì–´: ê¸°ë³¸ì ì¸ ì—£ì§€, ìƒ‰ìƒ ê²€ì¶œ\")\n",
        "        print(\"- ë‘ ë²ˆì§¸ ë ˆì´ì–´: ë” ë³µì¡í•œ íŒ¨í„´ ì¡°í•©\")\n",
        "        print(\"- ì„¸ ë²ˆì§¸ ë ˆì´ì–´: ê³ ìˆ˜ì¤€ íŠ¹ì§• (ê°ì²´ ë¶€ë¶„)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ í™œì„±í™” ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
        "        print(\"ğŸ’¡ ì´ëŠ” ëª¨ë¸ êµ¬ì¡°ë‚˜ TensorFlow ë²„ì „ ì´ìŠˆì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "        print(\"ğŸ“ ì£¼ìš” ê¸°ëŠ¥(ì˜ˆì¸¡)ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!\")\n"
      ],
      "metadata": {
        "id": "bScM15hz6gKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ® ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
        "def run_cnn_demo():\n",
        "    \"\"\"\n",
        "    CNN êµìœ¡ìš© ë°ëª¨ ë©”ì¸ ì‹¤í–‰\n",
        "    \"\"\"\n",
        "    print(\"ğŸ‰ ì§„ì§œ CNN êµìœ¡ìš© ë°ëª¨ ì‹œì‘!\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. CNN ëª¨ë¸ ìƒì„±\n",
        "    model = create_simple_cnn()\n",
        "\n",
        "    # 2. ëª¨ë¸ êµ¬ì¡° í™•ì¸\n",
        "    visualize_model_architecture(model)\n",
        "\n",
        "    # 3. ë¹ ë¥¸ í›ˆë ¨ (ë°ëª¨ìš©)\n",
        "    history = quick_train_with_dummy_data(model)\n",
        "\n",
        "    # 4. í•™ìŠµëœ í•„í„° ì‹œê°í™”\n",
        "    visualize_cnn_filters(model)\n",
        "\n",
        "    # 5. ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì˜ˆì¸¡\n",
        "    original_img, processed_img, image_batch, filename = upload_and_preprocess_image()\n",
        "\n",
        "    # 6. CNN ì˜ˆì¸¡ ë° ê²°ê³¼ ì‹œê°í™”\n",
        "    predict_and_visualize(model, original_img, processed_img, image_batch, filename)\n",
        "\n",
        "    # 7. CNN ë‚´ë¶€ ì‘ë™ ê³¼ì • ì‹œê°í™”\n",
        "    visualize_intermediate_activations(model, image_batch)\n",
        "\n",
        "    print(\"\\nğŸ“ CNN ë°ëª¨ ì™„ë£Œ!\")\n",
        "    print(\"ğŸ’¡ ì´ì œ CNNì´ ì–´ë–»ê²Œ ì´ë¯¸ì§€ë¥¼ 'ì´í•´'í•˜ëŠ”ì§€ ë³´ì…¨ìŠµë‹ˆë‹¤!\")\n",
        "\n",
        "# ğŸš€ ë°ëª¨ ì‹¤í–‰\n",
        "print(\"ğŸ“š CNN êµìœ¡ìš© ë°ëª¨ - ì‹¤ì œ ì‹ ê²½ë§ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜ ì²´í—˜\")\n",
        "print(\"ğŸ”¥ ì´ë²ˆì—ëŠ” ì§„ì§œ CNNì…ë‹ˆë‹¤!\")\n",
        "print()\n",
        "run_cnn_demo()"
      ],
      "metadata": {
        "id": "SFus-Shj6ijy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}